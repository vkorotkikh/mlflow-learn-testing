# MLOps Pipeline Configuration

# MLflow Configuration
mlflow:
  tracking_uri: "http://localhost:5000"
  experiment_name: "iris_classification_production"
  model_name: "iris_random_forest_production"
  artifact_location: "./mlruns"
  registry_store_uri: "sqlite:///mlflow.db"

# Kubeflow Configuration  
kubeflow:
  endpoint: "http://localhost:8080"
  namespace: "kubeflow-pipelines"
  pipeline_timeout: 3600  # seconds
  check_interval: 60      # seconds

# Airflow Configuration
airflow:
  dag_schedule: "@daily"
  max_active_runs: 1
  catchup: false
  email_on_failure: true
  email_on_retry: false
  retries: 2
  retry_delay: 300  # seconds

# Model Configuration
model:
  algorithm: "RandomForestClassifier"
  hyperparameters:
    n_estimators: [50, 100, 200]
    max_depth: [3, 5, 10, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    random_state: 42
  
  # Performance Thresholds
  thresholds:
    accuracy: 0.85
    precision: 0.85
    recall: 0.80
    f1_score: 0.82
    
  # Model Validation
  validation:
    test_size: 0.2
    cv_folds: 5
    stratify: true

# Data Configuration
data:
  dataset: "iris"
  source: "sklearn.datasets"
  features:
    - "sepal_length"
    - "sepal_width" 
    - "petal_length"
    - "petal_width"
  target: "species"
  classes:
    - "setosa"
    - "versicolor"
    - "virginica"

# Monitoring Configuration
monitoring:
  model_degradation_threshold: 0.05
  data_drift_threshold: 0.1
  performance_monitoring_interval: 3600  # seconds
  
  # Grafana Configuration
  grafana:
    url: "http://localhost:3000"
    admin_user: "admin"
    admin_password: "admin123"
    datasources:
      prometheus_url: "http://prometheus:9090"
      mlflow_url: "http://mlflow:5000"
    dashboards:
      - "mlops-overview"
      - "model-performance"
      - "infrastructure-monitoring"
      - "data-quality"
    
  # Prometheus Configuration
  prometheus:
    url: "http://localhost:9090"
    scrape_interval: "15s"
    evaluation_interval: "15s"
    retention: "30d"
    
  # Alerting Configuration
  alerts:
    email: "admin@company.com"
    slack_webhook: null
    alertmanager_url: "http://localhost:9093"
    alert_rules:
      model_accuracy_threshold: 0.85
      critical_accuracy_threshold: 0.75
      high_response_time_threshold: 5.0  # seconds
      failure_rate_threshold: 0.5  # 50%
    
# Infrastructure Configuration
infrastructure:
  docker:
    base_image: "python:3.9-slim"
    registry: "docker.io"
    namespace: "mlops"
    
  kubernetes:
    namespace: "mlops-production"
    resource_limits:
      cpu: "2"
      memory: "4Gi"
    resource_requests:
      cpu: "1"
      memory: "2Gi"

# Security Configuration
security:
  encrypt_artifacts: false
  model_signing: false
  access_control:
    enabled: false
    rbac_rules: []

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "mlops_pipeline.log"
  max_file_size: "10MB"
  backup_count: 5

# Environment-specific overrides
environments:
  development:
    mlflow:
      tracking_uri: "http://localhost:5000"
    model:
      thresholds:
        accuracy: 0.7
        precision: 0.7
    monitoring:
      alerts:
        email: "dev-team@company.com"
        
  staging:
    mlflow:
      tracking_uri: "http://mlflow-staging:5000"
    model:
      thresholds:
        accuracy: 0.8
        precision: 0.8
    monitoring:
      alerts:
        email: "staging-team@company.com"
        
  production:
    mlflow:
      tracking_uri: "http://mlflow-prod:5000"
    model:
      thresholds:
        accuracy: 0.9
        precision: 0.9
    monitoring:
      alerts:
        email: "ops-team@company.com"
        slack_webhook: "https://hooks.slack.com/services/..."


